# 4장. 처리율 제한 장치 설계

## 목차 

1. [처리율 제한 장치는 왜 필요할까?](#처리율-제한-장치는-왜-필요할까)
2. [처리율 제한 장치는 어디에 구현할까?](#처리율-제한-장치는-어디에-구현해야-할까)
3. [그렇다면 처리율 제한 장치는 어떻게 구현할까?](#그렇다면-처리율-제한-장치는-어떻게-구현할까)
4. [어디에 저장할까?](#어디에-저장할까)
5. [처리율을 넘어서는 요청은 어떻게 처리하는 게 좋을까?](#처리율을-넘어서는-요청은-어떻게-처리하는-게-좋을까)
6. [더 나아가서](#더-나아가서)


## 처리율 제한 장치는 왜 필요할까?

### 상황
- 쉽게 생각해볼 수 있는 상황으로는 트래픽 급증 시 서버 부하가 증가해 심각한 경우 서버가 다운될 수 있다.
- 여러 서비스를 운영하고 있는 상황에서 특정 하나의 서비스에 트래픽이 집중되면 다른 서비스는 트래픽이 적은 경우에도 하나의 서비스에 의해서 다른 서비스까지 사용자 경험에 악영향을 줄 수 있다.
- 반복적 요청이나 DoS공격과 같은 트래픽이 서버로 요청이 올 수 있다.

조금 더 구체적인 예시로도 생각해보자면 아래와 같은 경우가 있을 수 있겠다.
- 같은 IP주소로 여러 개의 계정을 만드는 경우
- 사용자가 무의미한 글을 연속적으로 게시할 경우
- aws의 s3 등의 third-party api를 사용하는 경우 악의적인 반복 요청에 의해 사용료가 많이 나올 수도 있다.

> 이러한 문제를 해결하기 위해서 처리율 제한 장치를 사용한다.  
> IP를 기준으로 혹은 엔드포인트를 기준으로 요청의 개수를 제한해두고 처리율을 조절할 수 있다.  

## 처리율 제한 장치는 어디에 구현해야 할까?

크게 클라이언트, 서버, 미들웨어 세 부분으로 나누어서 생각할 수 있다.

### 클라이언트
이 선택지는 좋은 선택지가 아니다. 왜냐하면 클라이언트는 쉽게 위변조가 가능하다.  
마음만 먹으면 클라이언트 측 코드는 모두 확인할 수 있고, 클라이언트를 거치지 않고 서버로 요청을 보낼 가능성도 있다.  
그렇기 때문에 클라이언트에 처리율 제한 장치를 구현하지 않는 것을 추천한다.

### 서버
그렇다면 다음 선택지로는 서버이다.  
서버 측에 둔다면 클라이언트에서 조작할 수 없기 때문에 클라이언트에 구현하는 것에 비해 안전하다고 볼 수 있다.  
하지만 이 방법은 분산 환경에서는 사용하기 부적절하다. 스티키 세션을 사용해 볼 수 있겠지만 아 벙법은 분산 환경의 장점을 감소 시키는 방법이기 때문에 좋은 방법이 아니라고 볼 수 있다.  
그래도 분산환경이 아니라면 좋은 선택지가 될 수 있다.

### 미들웨어
서버에 도달하기 전에 미들웨어에서 처리율 제한 장치를 구현한다면 단일 지점이 될 수 있기 때문에 분산환경에서도 사용할 수 있게 된다.  

> 그렇다고 해서 미들웨어에 처리율 제한 장치를 구현하는 것이 가장 좋은 선택지는 아니다.  
> 분산 환경이 필요 없고, 서버 간 부하가 크지 않다면 서버에 처리율 제한 장치를 구현하는 것도 좋은 방법이다.   
> 그러므로 서비스를 운영하는 상황에 따라 어느 부분에 처리율 제한 장치를 구현할 지 선택하는 것이 중요하다.  
> 그래도 클라이언트에 구현하는 것은 좋지 않은 것 같다.

## 그렇다면 처리율 제한 장치는 어떻게 구현할까?
처리율을 어떻게 제한할 지를 구현하는 알고리즘을 만들어야 한다.  
널리 알려진 인기 알고리으로는 다음과 같은 것들이 있다.
- 토큰 버킷 알고리즘
- 누출 버킷 알고리즘
- 고정 윈도 카운터 알고리즘
- 이동 윈도 로그 알고리즘
- 이동 윈도 카운터 알고리즘

> 여기서는 설계를 하는 방법에 초점을 맞춰 공부하고 있으므로 알고리즘을 활용하는 방법 자체는 이후에 따로 공부해볼 기회를 만들어봐야겠다.

### 토큰 버킷 알고리즘
이 알고리즘 이름 그대로 버킷에 토큰을 담아두고 토큰의 갯수만큼만 요청을 처리하는 방법이다.  
토큰은 일정시간마다 다시 채워지고 최대갯수인 상태에서 추가된 토큰은 무시된다.  
토큰이 0개인 상태에서 오는 요청은 버려지게 된다.  

여기서 버킷은 엔드포인트마다 둘 수도 있고, IP주소마다 둘 수도 있다.  
예를 들어, 사용자마다 하루에 한 번만 포스팅할 수 있고, 좋아요 버튼은 다섯 번까지만 누를 수 있다면, 사용자마다 2개의 버킷을 두어야 한다.

### 누출 버킷 알고리즘
이 알고리즘도 토큰 버킷 알고리즘과 비슷한데 토큰 버킷 알고리즘에 처리속도를 제한하는 방법이라고 생각하면 된다.  
보통 큐를 통해 구현하게 되고, 큐의 크기는 버킷의 크기와 똑같이 설정된다. 큐가 버킷의 역할을 한다고 생각하면 될것 같다.    
이어서 설명하자면 큐의 크기만큼만 요청을 받게 되고 일정시간마다 요청을 처리한다.  
이 때 큐가 가득 찬 상태에서는 추가 요청이 무시된다.

> 토큰 버킷 알고리즘과 누출 버킷 알고리즘 비교
> 토큰 버킷 알고리즘은 토큰의 잔여 갯수만큼 요청을 받고 처리 속도는 제어할 수 없다.  
> 반면 누출 알고리즘은 큐의 크기만큼 요청을 받고 처리 속도를 조절해서 요청을 처리할 수 있다.

### 고정 윈도 카운터 알고리즘
고정된 시간 간격으로 받아들일 수 있는 요청의 갯수를 제한하고, 넘치는 요청은 버려진다.  
예를 들어 매초마다 3개의 요청을 허용한다고 했을 때, 1:00:00 ~ 1:00:01 에 3개의 요청이 오면 모두 처리된다.  
그리고 1:00:01 ~ 1:00:02 에 5개의 요청이 오면 2개는 버려지게 된다.  

이 알고리즘은 일정시간마다 정해진 갯수의 요청만 처리할 수 있으므로 트래픽이 균등하다고 생각할 수 있다.  
위 예시의 시간을 더 쪼개서 생각해보자.  
1:00:00:30 ~ 1:00:01 에 3개의 요청이 오고 1:00:01 ~ 1:00:01:30 에 3개의 요청이 오면 모든 요청이 성공적으로 처리 되지만 1초동안 6개의 요청을 처리했음을 알 수 있다.  
이처럼 일시적으로 과도한 트래픽이 몰릴 경우 기대했던 처리 한도보다 많은 양을 처리하게 된다.

### 이동 윈도 로그 알고리즘
이 알고리즘은 고정 윈도 알고리즘의 문제를 해결할 수 있다.  
요청이 들어오면 저장 공간에 요청이 들어온 시간을 기록한다. 그리고 만료 시간도 함께 기록하게 된다.  
만약 만료 시간을 1분으로 기록하고 최대 2회의 요청만 처리할 수 있다고 하자.  
만약 로그에 보관된 시간이 두 개가 있고 아직 만료가 되지 않았다면 추가 요청은 무시되고 요청 시각만 로그에 기록된다.  
그리고 시간이 흘러 기록된 시간이 만료가 되어 로그에 1개의 시간만 존재한다면 추가적인 요청을 받을 수 있다.  
이렇게 고정적인 시간을 기준으로 처리율을 제한하는 것이 아니라 로그에 기록된 타임스탬프의 갯수로 판단하기 때문에 어느 시간을 기준으로 해도 처리율 한도를 넘지 않게 된다.  
저장 공간은 만료시간을 같이 기록할 수 있는 레디스를 많이 사용한다.

### 이동 윈도 카운터 알고리즘
이 알고리즘은 고정 윈도 카운터 알고리즘과 이동 윈도 로그 알고리즘을 결합한 알고리즘이다.  
이 알고리즘의 현재 처리한 요청의 개수는 현재 N분간의 요청 수 + 직전 N분 간의 요청 수 x 이동 윈도와 직전 N분이 겹치는 비율이다.  
예를 들어 직전 1분동안 5개의 요청이 왔고, 현재 1분동안 3개의 요청이 왔다고 가정해보자.  
현재 1분간의 요청 수는 3개이다. 그리고 직전 1분간의 요청수는 5개이고, 이동윈도는 1분이고 겹치는 직전 윈도를 42분이라고 가정하면 70%이다. 그럼 6.5개 정도의 처리율을 보이는 것이다. (소수점 처리는 자유이다.)  


## 어디에 저장할까?
처리율 제한 장치는 디스크보다 메모리에 저장하는 것이 성능에 유리하다. 왜냐하면 처리의 가능상태를 빨리 반환해줘야하는데 디스크는 메모리의 연산속도에 비해 많이 느리기 때문이다.  
메모리 저장소 중 레디스를 사용하는 것이 좋다. 카운터값을 증가시키고 타임아웃 값 저장 정책을 지원하기 때문이다.

## 처리율을 넘어서는 요청은 어떻게 처리하는 게 좋을까?
처리율을 넘어서는 요청들은 버리도록 처리했는데 만약 어떤 주문 시스템에 처리율 제한 장치를 설계한다면 어떡할까?  
주문 요청이 처리율을 넘어섰다고 요청을 버린다는 것은 사용자 경험에 좋지 않은 영향을 미칠 것이다.  
그렇기 떄문에 초과된 요청은 큐에 저장해 나중에 처리하는 방법도 있다.

## 더 나아가서

### 경쟁조건을 어떻게 해결할까?
분산환경이라면 처리율 제한 장치를 구현할 떄 경쟁 조건을 해결해야 한다.  
이 부분은 락을 사용해서 해결할수도 있지만, 락은 순서를 기다리며 실행되므로 시스템의 성능을 저하시킨다.  
단순 카운팅을 하는 방식은 레디스의 정렬 집합(Sorted Set)을 활용해 해결할 수 있다.  
> 이 방법은 나중에 실습해봐야겠다. 꼭 처리율 제한 장치가 아니더라도 다양한 부분에서!

### 동기화는 어떻게 해결할까?
분산환경이면서 수백만 사용자의 트래픽을 처리하려면 처리율 제한 장치는 한 대로는 무리가 있다.  
그래서 여러 대를 두게 되면 동기화가 필요해진다.  
동기화를 하는 방식으로는 스티키 세션을 활용하는 방법이 있으나 이 방법은 분산환경의 장점을 희석시키므로 추천하지 않는다.  
레디스를 활용해 단일 지점을 만들어서 해결하는 방법이 더 나은 해결책이다.

### 추가적으로
- 서비스가 커지면 전세계 사람들을 대상으로 서비스를 하게 된다. 이 경우에는 세계 곳곳에 서버를 설치하여 가까운 서버에 접속하게 하는 방법으로 성능을 최적화 할 수 있다.  
- 또한 처리율 제한 규칙이 잘 적용되는지 확인하기 위해 모니터링을 통해 확인하는 것도 중요하다.
- 경성 처리율(요청의 갯수는 임계치를 넘을 수 없음)과 연성 처리율(요청 개수는 잠시 동안은 임계치를 넘을 수 있음)을 고려해보자.

> 분산 환경의 데이터 동기화가 늘 고민이었는데 이 부분은 6잗 키 값 저장소 설계에서 배운다니 기다려보자.
> SPOF를 해결하기 위해 분산환경을 만드는데 분산환경의 동기화를 위해 다시 레디스로 단일 지점을 만든다.. 무한루프 느낌인데..
> 아직 잘 몰라서 하는 말이겠지만 계속 공부해나가야지.
